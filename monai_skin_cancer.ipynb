{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Cancer Training using MONAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "HAM10000 (\"Human Against Machine with 10000 training images\") is a popular data set of dermatoscopic images collected by [Harvard Dataverse](https://dataverse.harvard.edu/) from different populations.  It consists of 10015 images consisting of several diagnositic categories including: Actinic keratoses and intraepithelial carcinoma / Bowen's disease (akiec), basal cell carcinoma (bcc), benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses, bkl), dermatofibroma (df), melanoma (mel), melanocytic nevi (nv) and vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage, vasc).\n",
    "\n",
    "In this example we will demonstrate how to integrate the [MONAI](http://monai.io) framework into Amazon SageMaker using Pytorch and give example code of MONAI pre-processing transforms that can assist with imbalanced datasets and image transformations.  We will also show the code to invoke MONAI neural network architectures such as Densenet for image classification and explore structure of Pytorch code to train and serve the model within SageMaker.  Additionally, we will cover the SageMaker API calls to launch and manage the compute infrastructure for both model training and hosting for inference using the HAM10000 data set.\n",
    "\n",
    "For more information about the PyTorch in SageMaker, please visit [sagemaker-pytorch-containers](https://github.com/aws/sagemaker-pytorch-containers) and [sagemaker-python-sdk](https://github.com/aws/sagemaker-python-sdk) github repositories.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This notebook was created and tested on an ml.t2.medium notebook instance with 30 GB of EBS and conda_pytorch_latest_p36 kernel.\n",
    "\n",
    "Let's get started by creating a S3 bucket and uploading the [HAM10000 dataset](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DBW86T).\n",
    "\n",
    "<ol>\n",
    "<li>Create an S3 bucket in the same account as the Sagemaker notebook instance.\n",
    "<li>Download the HAMS10000 dataset at the URL above.\n",
    "<li>Select \"Access Dataset\" in top right, and select original format zip.\n",
    "<li>Upload dataset to the S3 bucket created in step 1.\n",
    "<li>Update the set.env file located in the current directory with the S3 location of the dataverse_files.zip.\n",
    "</ol>\n",
    "\n",
    "The code below will install MONAI framework and dependent packages and setup environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "# SPDX-License-Identifier: MIT-0\n",
    "\n",
    "!pip install -r source/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "env_path = Path('.') / 'set.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "skin_cancer_bucket=os.environ.get('SKIN_CANCER_BUCKET')\n",
    "skin_cancer_bucket_path=os.environ.get('SKIN_CANCER_BUCKET_PATH')\n",
    "skin_cancer_files=os.environ.get('SKIN_CANCER_FILES')\n",
    "skin_cancer_files_ext=os.environ.get('SKIN_CANCER_FILES_EXT')\n",
    "base_dir = os.environ.get('BASE_DIR')\n",
    "\n",
    "print('Skin Cancer Bucket: '+skin_cancer_bucket)\n",
    "print('Skin Cancer Bucket Prefix: '+skin_cancer_bucket_path)\n",
    "print('Skin Cancer Files: '+skin_cancer_files)\n",
    "print('Skin Cancer Files Ext: '+skin_cancer_files_ext)\n",
    "print('Base Dir: '+base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HAM10000 Data Transformation\n",
    "\n",
    "The transform_data.ipynb will download the dataverse_files.zip and perform transformations to build directories by class for training and validation sets from the meta-data.  It will also augment the data to create a more balanced data set across the classes for training.  The script will upload the transformed dataset HAM10000.tar.gz to the same S3 bucket identifed in set.env for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run source/transform_data.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "### Create Sagemaker session and S3 location for transformed HAM10000 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "inputs = sagemaker_session.upload_data(path='../HAM10000.tar.gz', bucket=skin_cancer_bucket, key_prefix=skin_cancer_bucket_path)\n",
    "print('input spec (in this case, just an S3 path): {}'.format(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "### Training\n",
    "\n",
    "The ```monai_skin_cancer.py``` script provides all the code we need for training and hosting a SageMaker model (model_fn function to load a model). The training script is very similar to a training script you might run outside of SageMaker, but you can access useful properties about the training environment through various environment variables, such as:\n",
    "\n",
    "* SM_MODEL_DIR: A string representing the path to the directory to write model artifacts to. These artifacts are uploaded to S3 for model hosting.\n",
    "* SM_NUM_GPUS: The number of gpus available in the current container.\n",
    "* SM_CURRENT_HOST: The name of the current container on the container network.\n",
    "* SM_HOSTS: JSON encoded list containing all the hosts .\n",
    "Supposing one input channel, 'training', was used in the call to the PyTorch estimator's fit() method, the following will be set, following the format SM_CHANNEL_[channel_name]:\n",
    "\n",
    "* SM_CHANNEL_TRAINING: A string representing the path to the directory containing data in the 'training' channel.\n",
    "For more information about training environment variables, please visit [SageMaker Containers](https://github.com/aws/sagemaker-containers).\n",
    "\n",
    "A typical training script loads data from the input channels, configures training with hyperparameters, trains a model, and saves a model to model_dir so that it can be hosted later. Hyperparameters are passed to your script as arguments and can be retrieved with an argparse.ArgumentParser instance.\n",
    "\n",
    "Because the SageMaker imports the training script, you should put your training code in a main guard (''if __name__=='__main__':'') if you are using the same script to host your model as we do in this example, so that SageMaker does not inadvertently run your training code at the wrong point in execution.\n",
    "\n",
    "MONAI includes deep neural networks such as UNet, DenseNet, GAN and others and provides sliding window inferences for large medical image volumes.  In the skin cancer image classification model, we train the MONAI DenseNet model on the skin cancer images for ten epochs while measuring loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize source/monai_skin_cancer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training in SageMaker\n",
    "\n",
    "The `PyTorch` class allows us to run our training function as a training job on SageMaker infrastructure.  We need to configure it with our training script, an IAM role, the number of training instances, the training instance type, and hyperparameters.  In this case we are going to run our training job on ```ml.c5.4xlarge``` instance.  But this example can be ran on one or multiple, cpu or gpu instances ([full list of available instances](https://aws.amazon.com/sagemaker/pricing/instance-types/)).  The hyperparameters parameter is a dict of values that will be passed to your training script -- you can see how to access these values in the ```monai_skin_cancer.py``` script above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(entry_point='monai_skin_cancer.py',\n",
    "                    source_dir='source',\n",
    "                    role=role,\n",
    "                    framework_version='1.5.0',\n",
    "                    py_version='py3',\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.c5.9xlarge',\n",
    "                    hyperparameters={\n",
    "                        'backend': 'gloo',\n",
    "                        'epochs': 1\n",
    "                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've constructed our PyTorch object, we can fit it using the HAM10000 dataset we uploaded to S3. SageMaker will download the data to the local filesystem, so our training script can simply read the data from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({'train': inputs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOST Model\n",
    "### Create real-time endpoint\n",
    "\n",
    "After training, we use the ``PyTorch`` estimator object to build and deploy a PyTorchPredictor. This creates a Sagemaker Endpoint -- a hosted prediction service that we can use to perform inference.\n",
    "\n",
    "As mentioned above we have implementation of `model_fn` in the monai_skin_cancer.py script that is required. We are going to use default implementations of `input_fn`, `predict_fn`, `output_fn` and `transform_fm` defined in [sagemaker-pytorch-containers](https://github.com/aws/sagemaker-pytorch-containers).\n",
    "\n",
    "The arguments to the deploy function allow us to set the number and type of instances that will be used for the Endpoint. These do not need to be the same as the values we used for the training job. For example, you can train a model on a set of GPU-based instances, and then deploy the Endpoint to a fleet of CPU-based instances, but you need to make sure that you return or save your model as a cpu model similar to what we did in monai_skin_cancer.py. Here we will deploy the model to a ```single ml.m5.xlarge``` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m5.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Validation Images for Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "print('Load Test Images for Inference')\n",
    "val_dir = os.path.join(base_dir, 'HAM10000/val_dir')\n",
    "class_names = sorted([x for x in os.listdir(val_dir) if os.path.isdir(os.path.join(val_dir, x))])\n",
    "num_class = len(class_names)\n",
    "image_files = [[os.path.join(val_dir, class_name, x)\n",
    "                for x in os.listdir(os.path.join(val_dir, class_name))[:1]] \n",
    "               for class_name in class_names]\n",
    "image_file_list = []\n",
    "image_label_list = []\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    image_file_list.extend(image_files[i])\n",
    "    image_label_list.extend([i] * len(image_files[i]))\n",
    "        \n",
    "num_total = len(image_label_list)\n",
    "image_width, image_height = Image.open(image_file_list[0]).size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MONAI Transform Image using Compose and Skin Cancer Dataset\n",
    "\n",
    "MONAI has transforms that support both Dictionary and Array format and are specialized for the high-dimensionality of medical images.  The transforms include several categories such as Crop & Pad, Intensity, IO, Post-processing, Spatial, and Utilities.  In the excerpt below, the Compose class chains a series of image transforms together and returns a single tensor of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from source.skin_cancer_dataset import SkinCancerDataset\n",
    "from monai.transforms import Compose, LoadPNG, Resize, AsChannelFirst, ScaleIntensity, ToTensor\n",
    "\n",
    "val_transforms = Compose([\n",
    "    LoadPNG(image_only=True),\n",
    "    AsChannelFirst(channel_dim=2),\n",
    "    ScaleIntensity(),\n",
    "    Resize(spatial_size=(64,64)),\n",
    "    ToTensor()\n",
    "])\n",
    "    \n",
    "val_ds = SkinCancerDataset(image_file_list, image_label_list, val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "We can now use the predictor to perform a real-time inference to classify skin cancer images.  Torch topk identifies the highest probability of skin cancer classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sample Inference Results By Class:')\n",
    "for i, val_data in enumerate(val_loader):\n",
    "    response = predictor.predict(val_data[0])\n",
    "    actual_label = val_data[1]\n",
    "    pred = torch.nn.functional.softmax(torch.tensor(response), dim=1)\n",
    "    top_p, top_class = torch.topk(pred, 1)\n",
    "    print('actual validation class: '+class_names[actual_label.numpy()[0]])\n",
    "    print('predicted class: '+class_names[top_class])\n",
    "    print('predicted class probablity: '+str(round(top_p.item(),2)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove endpoint (Optional)\n",
    "Delete the prediction endpoint to release the instance(s) hosting the model once finished with example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
